{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91541484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12656638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bd432ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "os.chdir('D:\\Traffic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47929723-21e1-4c4c-bb5e-5f4724c7cdf3",
   "metadata": {},
   "source": [
    "# Store data,labels in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff4e4c40-fa6d-463f-ac1c-9d38a2507cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[]\n",
    "labels = []\n",
    "# we have 43 classes\n",
    "classes =43\n",
    "cur_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94000211-097e-4e73-bf71-c142175d7386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Traffic'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9975b697-d7cd-4bdf-8a37-c85cd6a850d3",
   "metadata": {},
   "source": [
    "# Preprocess the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78451d67-55ff-4d56-8245-4a78c322057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(classes):\n",
    "    path = os.path.join(cur_path,'train',str(i))\n",
    "    images = os.listdir(path)\n",
    "    for a in images:\n",
    "        try:\n",
    "            image = Image.open(path + '\\\\' + a)\n",
    "            image = image.resize((30,30))\n",
    "            image = np.array(image)\n",
    "            data.append(image)\n",
    "            labels.append(i)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40646287-ceea-48cd-9197-f0e08f16d841",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Converting lists into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61501279-a258-45d4-b367-3156b9362587",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24364e57-35f8-48b3-8ea8-75d6dd2197fc",
   "metadata": {},
   "source": [
    "# Save label and data for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a4a2d2-4237-45f3-9950-b9aa69e5156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir(training)\n",
    "\n",
    "np.save('./training/data',data)\n",
    "np.save('./training/target',labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ce3814-96e8-4088-a347-ed9789155374",
   "metadata": {},
   "source": [
    "# LOAD DATA & LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cd3c7d-bf91-4500-9bd8-529170b91ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./training/data.npy')\n",
    "labels = np.load('./training/target.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1a5575-8482-4e6d-b86d-43ad98814285",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9889da09-e306-475c-8581-e42538bae5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e68b8da-24b6-4601-b842-0212f3215f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f75ba3-e177-4562-99bb-b8e2343f88ad",
   "metadata": {},
   "source": [
    "# Convert labels to onehot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993244c1-7b78-4622-8f92-d73959cb7f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 43)\n",
    "y_test = to_categorical(y_test, 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11356f02-77be-4f2a-9da2-c85994f786ec",
   "metadata": {},
   "source": [
    "## Now it's time to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c7c176-d781-495a-80c0-7b0e696e3e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "# We have 43 classes that's why we have defined 43 in the dense\n",
    "model.add(Dense(43, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a909c36-0062-4762-82d8-988a09129f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilation of the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9e409e-1974-41e7-8342-07bc55b68fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=epochs, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a3f8d4-4b13-456d-8fad-9aec02296756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy \n",
    "plt.figure(0)\n",
    "plt.plot(history.history['accuracy'], label='training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f795d-2e5c-4d00-929e-007183f482f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7bd68d-6e53-4159-ae3c-3efc1819d430",
   "metadata": {},
   "source": [
    "## LEt's do testing on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92854de-a181-413b-9ca6-6f793653e16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(testcsv):\n",
    "    y_test = pd.read_csv(testcsv)\n",
    "    label = y_test[\"ClassId\"].values\n",
    "    imgs = y_test[\"Path\"].values\n",
    "    data=[]\n",
    "    for img in imgs:\n",
    "        image = Image.open(img)\n",
    "        image = image.resize((30,30))\n",
    "        data.append(np.array(image))\n",
    "    X_test=np.array(data)\n",
    "    return X_test,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab6d9ac-0f50-4fd8-829b-99aadb03d60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, label = testing('Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd7e04b-e581-4a81-8b7b-22a97e7aeda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.argmax(model.predict(X_test),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe8ff65-4456-42c9-a495-a2d501f38e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebea76ae-592b-4617-bbe6-c3e389522c9e",
   "metadata": {},
   "source": [
    "## Accuracy with the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8793ee00-8150-433c-ad7a-1762463fa906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(label, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c6d63b-d4bc-4dba-9217-3d8af8022600",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8434ee-817d-4f0f-9f33-2a0dc58f9a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./training/TSR.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ac85e8-7110-43dd-9662-919ad715bc31",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd71571-cbc0-4a21-88b1-ab4d9d5c5c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'D:\\Traffic')\n",
    "from keras.models import load_model\n",
    "model = load_model('./training/TSR.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5703e62c-d0e8-4106-a678-1fecc9c97bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes of trafic signs\n",
    "classes = { 0:'Speed limit (20km/h)',\n",
    "            1:'Speed limit (30km/h)', \n",
    "            2:'Speed limit (50km/h)', \n",
    "            3:'Speed limit (60km/h)', \n",
    "            4:'Speed limit (70km/h)', \n",
    "            5:'Speed limit (80km/h)', \n",
    "            6:'End of speed limit (80km/h)', \n",
    "            7:'Speed limit (100km/h)', \n",
    "            8:'Speed limit (120km/h)', \n",
    "            9:'No passing', \n",
    "            10:'No passing veh over 3.5 tons', \n",
    "            11:'Right-of-way at intersection', \n",
    "            12:'Priority road', \n",
    "            13:'Yield', \n",
    "            14:'Stop', \n",
    "            15:'No vehicles', \n",
    "            16:'Veh > 3.5 tons prohibited', \n",
    "            17:'No entry', \n",
    "            18:'General caution', \n",
    "            19:'Dangerous curve left', \n",
    "            20:'Dangerous curve right', \n",
    "            21:'Double curve', \n",
    "            22:'Bumpy road', \n",
    "            23:'Slippery road', \n",
    "            24:'Road narrows on the right', \n",
    "            25:'Road work', \n",
    "            26:'Traffic signals', \n",
    "            27:'Pedestrians', \n",
    "            28:'Children crossing', \n",
    "            29:'Bicycles crossing', \n",
    "            30:'Beware of ice/snow',\n",
    "            31:'Wild animals crossing', \n",
    "            32:'End speed + passing limits', \n",
    "            33:'Turn right ahead', \n",
    "            34:'Turn left ahead', \n",
    "            35:'Ahead only', \n",
    "            36:'Go straight or right', \n",
    "            37:'Go straight or left', \n",
    "            38:'Keep right', \n",
    "            39:'Keep left', \n",
    "            40:'Roundabout mandatory', \n",
    "            41:'End of no passing', \n",
    "            42:'End no passing veh > 3.5 tons' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f0a91c-c5e4-4cdd-9de0-deb507eb1872",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def test_on_img(img):\n",
    "    data=[]\n",
    "    image = Image.open(img)\n",
    "    image = image.resize((30,30))\n",
    "    data.append(np.array(image))\n",
    "    X_test=np.array(data)\n",
    "    Y_pred = np.argmax(model.predict(X_test),axis=1)\n",
    "    return image,Y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57674812-1592-4dba-8e6b-939d1d63b5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot,prediction = test_on_img(r'D:\\Traffic\\Test\\00812.png')\n",
    "s = [str(i) for i in prediction] \n",
    "a = int(\"\".join(s)) \n",
    "print(\"Predicted traffic sign is: \", classes[a])\n",
    "plt.imshow(plot)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74482db0-c12d-4727-85c3-755c58e51e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569d69e7-b584-4df3-a451-038bcd44b9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
